# 论文入库基本信息

---
<center>1</center>

---

<<<<<<< Updated upstream
<<<<<<< HEAD

=======
标题：互联网虚假信息检测进展与展望

作者：曹娟、盛强、亓鹏
>>>>>>> ab3fa7b2894fae351fd8463004f58c8c813a14c8

机构： 中国科学院计算技术研究所

<<<<<<< HEAD
标题：Attention is All you Need

作者：Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Łukasz Kaiser, Illia Polosukhin

期刊：NIPS

发表时间：2017

引用：

方向：Transformer
=======
期刊：中国计算机学会 CCCF2020

发表时间：2020
=======
标题：The expectation-maximization algorithm

作者：T.K. Moon

机构：Utah State University, Logan, UT, US

期刊：IEEE Signal Processing Magazine

发表时间：1996
>>>>>>> Stashed changes

引用：Moon T K. The expectation-maximization algorithm[J]. IEEE Signal processing magazine, 1996, 13(6): 47-60.

<<<<<<< Updated upstream
方向：虚假信息检测
>>>>>>> ab3fa7b2894fae351fd8463004f58c8c813a14c8


标题：Poly-encoders: architectures and pre-training strategies for fast and accurate multi-sentence scoring

作者：Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, Jason Weston

期刊：ICLR2020
发表时间：2020

引用：Humeau S, Shuster K, Lachaux M A, et al. Poly-encoders: Transformer architectures and pre-training strategies for fast and accurate multi-sentence scoring[J]. arXiv preprint arXiv:1905.01969, 2019.

方向：对话

=======
方向：机器学习
>>>>>>> Stashed changes
