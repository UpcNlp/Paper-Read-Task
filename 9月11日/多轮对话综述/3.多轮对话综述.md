对话系统一般可以被表述为一个编码器-解码器框架，其中编码器被用来理解对话背景，而解码器则用于给出回应。编码器可以是LSTM这样的循环神经网络，或者是BERT这样的预训练语言模型
对话模型框架    
    1.早期的方法。使用Encoder将上下文（Context）编码，然后Decoder用来计算候选的回答（Answer）和Context的匹配度，类似相似度计算。
    2.基于注意力配对机制。引入注意力机制，计算Answer与Context中的关键语料的匹配程度。
    3.基于预训练模型。Answer和Context拼接起来编码。[CLS]Context[SEP]Answer[SEP]，然后做一个二分类，是or否为该Context的答案。
    基于预训练模型的方法超过了早期的两种方法。但是大模型的经典问题，实际应用响应慢。
用于多轮对话的预训练模型
        问题：Context很难体现非常独特的文本特征来支撑和Answer的匹配，其次，如果是特定领域，使用通用语料预训练的大模型就没什么用了。
        解决：三种策略：通用预训练（Masked LM， n-gram LM）、领域感知预训练（Retrieval、Generation）和任务导向预训练（Cross-utterance、Inner-utterance ）
            通用预训练：传统方法，大规模通用语料预训练，下游任务微调。
            领域感知预训练：把大规模通用语料换成对话的语料。
            任务导向预训练：重新设计适合于对话的预训练任务。例如：
                1）Whang等人（2021年）提出了各种语篇操作策略，包括语篇插入、删除和搜索，以保持对话的连贯性。
                2）Xu等人（2021a）同样引入了四个自我监督的任务，明确地对交叉语料关系进行建模，以提高语料之间的连贯性和一致性，包括下一个会话预测、语料恢复、不连贯性检测和一致性辨别，
                3）Zhang和Zhao（2021）引入了一个句子骨干正则化任务作为正则化，以提高总结的主语-动词-宾语三联体的事实正确性。
                4）Zhao等人（2020）提出了词序恢复和屏蔽词恢复，以加强对词之间的顺序依存关系的理解。
    另外的方向：为模型提供额外的信息，例如：
                1）辅助的语言学知识：语法，话语信息，说话人关系，领域知识，从知识图谱加强推理能力，基于人的属性，如说话人身份、对话主题、说话人情绪，场景信息等
                2）多模态，比如视觉和语音信息。



