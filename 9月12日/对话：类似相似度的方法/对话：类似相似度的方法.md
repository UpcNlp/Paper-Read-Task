在Ubuntu对话语料库进行了一系列实验，包括一些早期的模型，和本论文提出的模型。
对应9.11综述中最早期的方法：类似相似度计算的对话实现方式。
1.评价指标
    数据集的2%作为测试集，一个Context有多个候选的Answer，这些Answer按照匹配程度进行了排名，是有顺序的。有一个最佳Answer，模型选择了前k个Answer就算正确。这个数量被表示为Recall@k。（n，k）为（2，1）、（10，1）、（10，2）和（10，5）。
2.任务
    p=g(context, response)，计算每一对的概率，进行排序
3.更早期的模型
    TF-IDF：正确的Answer往往比不正确的Answer与Context共享更多的词：方法是，分别计算Context和每个候选Answer的TF-IDF向量，计算他们之间的余弦相似度。排序。
    基于神经网络：使用Rnn、lstm等对Context和Answer进行嵌入。用于嵌入的神经网络记作f，Context记作C，Answer记作A。Ct×M×A+b，再经过一个sigmoid，也就是A和C相乘，经过一个全连接再sigmoid得到评分。排序。
4.本文基于神经网络的方法使用LSTM，CNN，Bi-LSTM做了实验。并没有提出新的模型架构，单模型中，LSTM的效果最好。用于嵌入的神经网络，为Answer和Context单独学习参数的效果比共享参数的效果要差。对多个模型的预测进行平均可以进一步提高性能，最好的效果是由11个LSTM，7个Bi-LSTM和10个CNN随机初始化参数训练得到的集合体。