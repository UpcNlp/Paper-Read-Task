新闻文本常包含几十至几百条句子，因字符数多、包含较多与主题无关信息，影响分类性能。对此，提出了结合注意力机制的长文本分类方法。首先将文本的句子表示为段落向量，再构建段落向量与文本类别的神经网络
注意力模型，用于计算句子的注意力，将句子注意力的均方差作为其对类别的贡献度，进行句子过滤，然后构建卷积神经网络( CNN) 分类模型，分别将过滤后的文本及其注意力矩阵作为网络输入。模型用max pooling 进行特征
过滤，用随机dropout 防止过拟合。

首先将文本的句子表示为段落向量，再构建段落向量与文本类别的神经网络注意力模型，用于计算句子的注意力，将句子注意力的均方差作为其对类别的贡献度，进行句子过滤，然后构建卷积神经网络( CNN) 分类模型，分别将
过滤后的文本及其注意力矩阵作为网络输入。
数据集：长文本以及长文本所属类别，用于计算句子的注意力。例如，一个长文本可以分为n个句子，每个句子经过单层神经网络并Softmax归一化处理，得到1*m的向量，m为所有的类别的数目。向量中第i维的数据表示该句子属
于第i类的概率，概率越大，表示属于第i类的置信度越高，对概率最大值也较低的句子，认为该句子对于文本分类的贡献度不大。所以，要使用均方差进行筛选，具体流程见图2。最后经过CNN卷积神经网络，将所有通过筛选的句子
以及词的注意力向量作为输入（对任意文本D，首先将其词向量拼接成 KEYS 矩阵，然后将句子注意力作为句中词的注意力，拼接词注意力向量成 ATTS 矩 阵。），分别经过卷积层，池化层得到长文本的类别，计算其准确率，见图3

比如：在一个三分类问题中，设句子d1、d2的注意力分别为( 0．36，0．30，0．34) ，( 0．43，0．29，0．28) ，a 为0．33，则Cd1、Cd2分别为0．00063、0.004 7，即句子d2对分类贡献度更大（c的计算方法见图1）。

图4表示的是通过设置不同的threshold，文本长度、句子长度和词项数的变化
图5表示的是在不同的threshold下，Baseline和CNN_A分类正确率的走势
通过图5，得出结论，该现象表明，由于句子过滤的粒度太粗，当文本保留的词项达到一定阈值时，再进行句子过滤可能使某些文本的特征损失过大，导致分类正确率大幅降

