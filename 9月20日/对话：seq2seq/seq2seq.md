论文提出了3个模型:
    检索模型（Retriever）
        就是从候选集中选取最合适的句子作为机器人当前的答复，训练时，候选集只有给定的一句response；在做推断时，候选集由训练集中的所有response组成。具体打分/排序模型使用 Poly-encoder(9月15日论文)
    生成模型（Generator）
        生成模型是标准的 seq2seq 结构，只是用了标准的 Transformer 层，以及 encoder 层数少，decoder 层数多的设计。decoding阶段一般使用beam Search或sampling方法。
        控制生成回复的最小长度。作者尝试了两种方法：
        Minimum length：要求回复长度必须大于设定的值。长度不达标时，强制不产生结束 token；
        Predictive length：把长度分成四段，例如 <10, <20, <30, 和 >30 tokens，然后利用四分类模型预测当前回复应该落在哪个长度段。
        屏蔽重复的子序列（Subsequence Blocking）：不允许产生当前句子和前面对话（context）中已经存在的 3-grams。
    检索+生成（Retrieve and Refine）
         RetNRef先利用检索模型检索出一个结果，然后把检索出的结果拼接到context后面，用一个特殊的分割符和context分隔，然后整体作为generator模型的输入。这样做的目的是期望生成模型能学习到在合适的时候从检索结果中copy词或词组。      
         检索出的结果具体是怎么得到的？：
            1.利用训练好的poly-encoder检索模型直接从训练集中检索出得分最高的回复，作为结果；
            2.从外部的大知识库如Wiki中检索，具体做法如下：
                    分别利用当前对话topic（对话topic会事先告知）和最后两轮对话，各自检索出top-7的文章；
                    把 3*7=21 篇文章各自分句，然后把各自文章的 title 追加到每个句子最前面，获得很多候选句子；
                    再利用poly-encoder结构的模型对候选句子排序，最终使用 top-1 的句子作为检索结果；
                    同时还会训练一个单独的分类器来判断是否需要从知识库中检索知识。回复某些对话context可以不需要额外知识，这时候就不用追加检索结果。

            
            作者提出了名为α-blending的训练策略：训练时以α%的概率把检索结果替换为实际回复。这样模型就会被吸引去关注检索部分了。